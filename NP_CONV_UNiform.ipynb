{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "NP-CONV-UNiform.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuaigezhu/starDist/blob/master/NP_CONV_UNiform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMHHW9B22AN0",
        "colab_type": "code",
        "colab": {},
        "outputId": "6d0dd204-a6a5-4291-cc37-1ddc30d01232"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from math import pi\n",
        "from random import randint\n",
        "import glob\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QP39Z4w2AOA",
        "colab_type": "text"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH8hT1CF2AOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_mlp(input, output_sizes, variable_scope):\n",
        "  \"\"\"Apply MLP to the final axis of a 3D tensor (reusing already defined MLPs).\n",
        "  \n",
        "  Args:\n",
        "    input: input tensor of shape [B,n,d_in].\n",
        "    output_sizes: An iterable containing the output sizes of the MLP as defined \n",
        "        in `basic.Linear`.\n",
        "    variable_scope: String giving the name of the variable scope. If this is set\n",
        "        to be the same as a previously defined MLP, then the weights are reused.\n",
        "    \n",
        "  Returns:\n",
        "    tensor of shape [B,n,d_out] where d_out=output_sizes[-1]\n",
        "  \"\"\"\n",
        "  # Get the shapes of the input and reshape to parallelise across observations\n",
        "  batch_size, _, filter_size = input.shape.as_list()\n",
        "  output = tf.reshape(input, (-1, filter_size))\n",
        "  output.set_shape((None, filter_size))\n",
        "\n",
        "  # Pass through MLP\n",
        "  with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
        "    for i, size in enumerate(output_sizes[:-1]):\n",
        "      output = tf.nn.relu(\n",
        "          tf.layers.dense(output, size, name=\"layer_{}\".format(i)))\n",
        "\n",
        "    # Last layer without a ReLu\n",
        "    output = tf.layers.dense(\n",
        "        output, output_sizes[-1], name=\"layer_{}\".format(i + 1))\n",
        "\n",
        "  # Bring back into original shape\n",
        "  output = tf.reshape(output, (batch_size, -1, output_sizes[-1]))\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMsvvlU_2AOO",
        "colab_type": "text"
      },
      "source": [
        "### **Deterministic Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFRPxwfF2AOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeterministicEncoder(object):\n",
        "  \"\"\"The Deterministic Encoder.\"\"\"\n",
        "\n",
        "  def __init__(self, output_sizes, attention):\n",
        "    \"\"\"(A)NP deterministic encoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the encoding MLP.\n",
        "      attention: The attention module.\n",
        "    \"\"\"\n",
        "    self._output_sizes = output_sizes\n",
        "    self._attention = attention\n",
        "\n",
        "  def __call__(self, context_x, context_y, target_x):\n",
        "    \"\"\"Encodes the inputs into one representation.\n",
        "\n",
        "    Args:\n",
        "      context_x: Tensor of shape [B,observations,d_x]. For this 1D regression\n",
        "          task this corresponds to the x-values.\n",
        "      context_y: Tensor of shape [B,observations,d_y]. For this 1D regression\n",
        "          task this corresponds to the y-values.\n",
        "      target_x: Tensor of shape [B,target_observations,d_x]. \n",
        "          For this 1D regression task this corresponds to the x-values.\n",
        "\n",
        "    Returns:\n",
        "      The encoded representation. Tensor of shape [B,target_observations,d]\n",
        "    \"\"\"\n",
        "\n",
        "    # Concatenate x and y along the filter axes\n",
        "    encoder_input = tf.concat([context_x, context_y], axis=-1)\n",
        "\n",
        "    # Pass final axis through MLP\n",
        "    hidden = batch_mlp(encoder_input, self._output_sizes, \n",
        "                       \"deterministic_encoder\")\n",
        "\n",
        "    # Apply attention\n",
        "    with tf.variable_scope(\"deterministic_encoder\", reuse=tf.AUTO_REUSE):\n",
        "        hidden = self._attention(context_x, target_x, hidden)\n",
        "\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfQwI7Vm2AOW",
        "colab_type": "text"
      },
      "source": [
        "### **Latent Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGcdu9yC2AOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LatentEncoder(object):\n",
        "  \"\"\"The Latent Encoder.\"\"\"\n",
        "\n",
        "  def __init__(self, output_sizes, num_latents):\n",
        "    \"\"\"(A)NP latent encoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the encoding MLP.\n",
        "      num_latents: The latent dimensionality.\n",
        "    \"\"\"\n",
        "    self._output_sizes = output_sizes\n",
        "    self._num_latents = num_latents\n",
        "\n",
        "  def __call__(self, x, y):\n",
        "    \"\"\"Encodes the inputs into one representation.\n",
        "\n",
        "    Args:\n",
        "      x: Tensor of shape [B,observations,d_x]. For this 1D regression\n",
        "          task this corresponds to the x-values.\n",
        "      y: Tensor of shape [B,observations,d_y]. For this 1D regression\n",
        "          task this corresponds to the y-values.\n",
        "\n",
        "    Returns:\n",
        "      A normal distribution over tensors of shape [B, num_latents]\n",
        "    \"\"\"\n",
        "\n",
        "    # Concatenate x and y along the filter axes\n",
        "    encoder_input = tf.concat([x, y], axis=-1)\n",
        "\n",
        "    # Pass final axis through MLP\n",
        "    print('encoder')\n",
        "    print(encoder_input.shape)\n",
        "    hidden = batch_mlp(encoder_input, self._output_sizes, \"latent_encoder\")\n",
        "    \n",
        "    # Aggregator: take the mean over all points\n",
        "    hidden = tf.reduce_mean(hidden, axis=1)\n",
        "    \n",
        "    # Have further MLP layers that map to the parameters of the Gaussian latent\n",
        "    with tf.variable_scope(\"latent_encoder\", reuse=tf.AUTO_REUSE):\n",
        "      # First apply intermediate relu layer \n",
        "      hidden = tf.nn.relu(\n",
        "          tf.layers.dense(hidden, \n",
        "                          (self._output_sizes[-1] + self._num_latents)/2,\n",
        "                          name=\"penultimate_layer\"))\n",
        "      # Then apply further linear layers to output latent mu and log sigma\n",
        "      mu = tf.layers.dense(hidden, self._num_latents, name=\"mean_layer\")\n",
        "      log_sigma = tf.layers.dense(hidden, self._num_latents, name=\"std_layer\")\n",
        "      \n",
        "    # Compute sigma\n",
        "    sigma = 0.1 + 0.9 * tf.sigmoid(log_sigma)\n",
        "\n",
        "    return tf.contrib.distributions.Normal(loc=mu, scale=sigma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo-ECycz2AOg",
        "colab_type": "text"
      },
      "source": [
        "### **Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViOeyrAD2AOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(object):\n",
        "  \"\"\"The Decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, output_sizes):\n",
        "    \"\"\"(A)NP decoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the decoder MLP \n",
        "          as defined in `basic.Linear`.\n",
        "    \"\"\"\n",
        "    self._output_sizes = output_sizes\n",
        "\n",
        "  def __call__(self, representation, target_x):\n",
        "    \"\"\"Decodes the individual targets.\n",
        "\n",
        "    Args:\n",
        "      representation: The representation of the context for target predictions. \n",
        "          Tensor of shape [B,target_observations,?].\n",
        "      target_x: The x locations for the target query.\n",
        "          Tensor of shape [B,target_observations,d_x].\n",
        "\n",
        "    Returns:\n",
        "      dist: A multivariate Gaussian over the target points. A distribution over\n",
        "          tensors of shape [B,target_observations,d_y].\n",
        "      mu: The mean of the multivariate Gaussian.\n",
        "          Tensor of shape [B,target_observations,d_x].\n",
        "      sigma: The standard deviation of the multivariate Gaussian.\n",
        "          Tensor of shape [B,target_observations,d_x].\n",
        "    \"\"\"\n",
        "    # concatenate target_x and representation\n",
        "    hidden = tf.concat([representation, target_x], axis=-1)\n",
        "\n",
        "    print('decoder')\n",
        "    print(hidden.shape)\n",
        "    # Pass final axis through MLP\n",
        "    hidden = batch_mlp(hidden, self._output_sizes, \"decoder\")\n",
        "\n",
        "    # Get the mean an the variance\n",
        "    mu, log_sigma = tf.split(hidden, 2, axis=-1)\n",
        "\n",
        "    # Bound the variance\n",
        "    sigma = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
        "\n",
        "    # Get the distribution\n",
        "    dist = tf.contrib.distributions.MultivariateNormalDiag(\n",
        "        loc=mu, scale_diag=sigma)\n",
        "\n",
        "    return dist, mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wRIVN8m2AOn",
        "colab_type": "text"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K10ypKka2AOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LatentModel(object):\n",
        "  \"\"\"The (A)NP model.\"\"\"\n",
        "\n",
        "  def __init__(self, latent_encoder_output_sizes, num_latents,\n",
        "               decoder_output_sizes, use_deterministic_path=True, \n",
        "               deterministic_encoder_output_sizes=None, attention=None):\n",
        "    \"\"\"Initialises the model.\n",
        "\n",
        "    Args:\n",
        "      latent_encoder_output_sizes: An iterable containing the sizes of hidden \n",
        "          layers of the latent encoder.\n",
        "      num_latents: The latent dimensionality.\n",
        "      decoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
        "          the decoder. The last element should correspond to d_y * 2\n",
        "          (it encodes both mean and variance concatenated)\n",
        "      use_deterministic_path: a boolean that indicates whether the deterministic\n",
        "          encoder is used or not.\n",
        "      deterministic_encoder_output_sizes: An iterable containing the sizes of \n",
        "          hidden layers of the deterministic encoder. The last one is the size \n",
        "          of the deterministic representation r.\n",
        "      attention: The attention module used in the deterministic encoder.\n",
        "          Only relevant when use_deterministic_path=True.\n",
        "    \"\"\"\n",
        "    self._latent_encoder = LatentEncoder(latent_encoder_output_sizes, \n",
        "                                         num_latents)\n",
        "    self._decoder = Decoder(decoder_output_sizes)\n",
        "    self._use_deterministic_path = use_deterministic_path\n",
        "    if use_deterministic_path:\n",
        "      self._deterministic_encoder = DeterministicEncoder(\n",
        "          deterministic_encoder_output_sizes, attention)\n",
        "    \n",
        "\n",
        "  def __call__(self, query, num_targets, target_y=None, test_target_y=None):\n",
        "    \"\"\"Returns the predicted mean and variance at the target points.\n",
        "\n",
        "    Args:\n",
        "      query: Array containing ((context_x, context_y), target_x) where:\n",
        "          context_x: Tensor of shape [B,num_contexts,d_x]. \n",
        "              Contains the x values of the context points.\n",
        "          context_y: Tensor of shape [B,num_contexts,d_y]. \n",
        "              Contains the y values of the context points.\n",
        "          target_x: Tensor of shape [B,num_targets,d_x]. \n",
        "              Contains the x values of the target points.\n",
        "      num_targets: Number of target points.\n",
        "      target_y: The ground truth y values of the target y. \n",
        "          Tensor of shape [B,num_targets,d_y].\n",
        "\n",
        "    Returns:\n",
        "      log_p: The log_probability of the target_y given the predicted\n",
        "          distribution. Tensor of shape [B,num_targets].\n",
        "      mu: The mean of the predicted distribution. \n",
        "          Tensor of shape [B,num_targets,d_y].\n",
        "      sigma: The variance of the predicted distribution.\n",
        "          Tensor of shape [B,num_targets,d_y].\n",
        "    \"\"\"\n",
        "\n",
        "    (context_x, context_y), target_x = query\n",
        "\n",
        "    # Pass query through the encoder and the decoder\n",
        "    prior = self._latent_encoder(context_x, context_y)\n",
        "    \n",
        "    # For training, when target_y is available, use targets for latent encoder.\n",
        "    # Note that targets contain contexts by design.\n",
        "    if target_y is None:\n",
        "      latent_rep = prior.sample()\n",
        "    # For testing, when target_y unavailable, use contexts for latent encoder.\n",
        "    else:\n",
        "      posterior = self._latent_encoder(target_x, target_y)\n",
        "      latent_rep = posterior.sample()\n",
        "    latent_rep = tf.tile(tf.expand_dims(latent_rep, axis=1),\n",
        "                         [1, num_targets, 1])\n",
        "    if self._use_deterministic_path:\n",
        "      deterministic_rep = self._deterministic_encoder(context_x, context_y,\n",
        "                                                      target_x)\n",
        "      representation = tf.concat([deterministic_rep, latent_rep], axis=-1)\n",
        "    else:\n",
        "      representation = latent_rep\n",
        "      \n",
        "    dist, mu, sigma = self._decoder(representation, target_x)\n",
        "    \n",
        "    # If we want to calculate the log_prob for training we will make use of the\n",
        "    # target_y. At test time the target_y is not available so we return None.\n",
        "    if target_y is not None:\n",
        "      log_p = dist.log_prob(target_y)\n",
        "      posterior = self._latent_encoder(target_x, target_y)\n",
        "      kl = tf.reduce_sum(\n",
        "          tf.contrib.distributions.kl_divergence(posterior, prior), \n",
        "          axis=-1, keepdims=True)\n",
        "      kl = tf.tile(kl, [1, num_targets])\n",
        "      loss = - tf.reduce_mean(log_p - kl / tf.cast(num_targets, tf.float32))\n",
        "      LL = tf.reduce_mean(log_p, keep_dims=False)\n",
        "    else:\n",
        "      log_p = dist.log_prob(test_target_y)\n",
        "      posterior = self._latent_encoder(target_x, test_target_y)\n",
        "      kl = tf.reduce_sum(\n",
        "          tf.contrib.distributions.kl_divergence(posterior, prior), \n",
        "          axis=-1, keepdims=True)\n",
        "      kl = tf.tile(kl, [1, num_targets])\n",
        "      loss = - tf.reduce_mean(log_p - kl / tf.cast(num_targets, tf.float32))\n",
        "      #validation_context_loss = - tf.reduce_mean(log_p[:,int(0.5*num_targets):] - kl / tf.cast(num_targets, tf.float32))\n",
        "      #validation_noncontext_loss =  - tf.reduce_mean(log_p - kl / tf.cast(num_targets, tf.float32))\n",
        "      LL = None\n",
        "        #con_y = pred_y[:,:int(0.5 * test_num_total_points)] - target_y[:,:int(0.5 * test_num_total_points)]\n",
        "      #tar_y = pred_y[:,int(0.5 * test_num_total_points):] - target_y[:,int(0.5 * test_num_total_points):]\n",
        "\n",
        "    return mu, sigma, log_p, LL, kl, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xEZsPkZ2AOr",
        "colab_type": "text"
      },
      "source": [
        "### **Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sQUX8nU2AOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def uniform_attention(q, v):\n",
        "  \"\"\"Uniform attention. Equivalent to np.\n",
        "\n",
        "  Args:\n",
        "    q: queries. tensor of shape [B,m,d_k].\n",
        "    v: values. tensor of shape [B,n,d_v].\n",
        "    \n",
        "  Returns:\n",
        "    tensor of shape [B,m,d_v].\n",
        "  \"\"\"\n",
        "  total_points = tf.shape(q)[1]\n",
        "  rep = tf.reduce_mean(v, axis=1, keepdims=True)  # [B,1,d_v]\n",
        "  rep = tf.tile(rep, [1, total_points, 1])\n",
        "  return rep\n",
        "\n",
        "def laplace_attention(q, k, v, scale, normalise):\n",
        "  \"\"\"Computes laplace exponential attention.\n",
        "\n",
        "  Args:\n",
        "    q: queries. tensor of shape [B,m,d_k].\n",
        "    k: keys. tensor of shape [B,n,d_k].\n",
        "    v: values. tensor of shape [B,n,d_v].\n",
        "    scale: float that scales the L1 distance.\n",
        "    normalise: Boolean that determines whether weights sum to 1.\n",
        "    \n",
        "  Returns:\n",
        "    tensor of shape [B,m,d_v].\n",
        "  \"\"\"\n",
        "  k = tf.expand_dims(k, axis=1)  # [B,1,n,d_k]\n",
        "  q = tf.expand_dims(q, axis=2)  # [B,m,1,d_k]\n",
        "  unnorm_weights = - tf.abs((k - q) / scale)  # [B,m,n,d_k]\n",
        "  unnorm_weights = tf.reduce_sum(unnorm_weights, axis=-1)  # [B,m,n]\n",
        "  if normalise:\n",
        "    weight_fn = tf.nn.softmax\n",
        "  else:\n",
        "    weight_fn = lambda x: 1 + tf.tanh(x)\n",
        "  weights = weight_fn(unnorm_weights)  # [B,m,n]\n",
        "  rep = tf.einsum('bik,bkj->bij', weights, v)  # [B,m,d_v]\n",
        "  return rep\n",
        "\n",
        "\n",
        "def dot_product_attention(q, k, v, normalise):\n",
        "  \"\"\"Computes dot product attention.\n",
        "\n",
        "  Args:\n",
        "    q: queries. tensor of  shape [B,m,d_k].\n",
        "    k: keys. tensor of shape [B,n,d_k].\n",
        "    v: values. tensor of shape [B,n,d_v].\n",
        "    normalise: Boolean that determines whether weights sum to 1.\n",
        "    \n",
        "  Returns:\n",
        "    tensor of shape [B,m,d_v].\n",
        "  \"\"\"\n",
        "  d_k = tf.shape(q)[-1]\n",
        "  scale = tf.sqrt(tf.cast(d_k, tf.float32))\n",
        "  unnorm_weights = tf.einsum('bjk,bik->bij', k, q) / scale  # [B,m,n]\n",
        "  if normalise:\n",
        "    weight_fn = tf.nn.softmax\n",
        "  else:\n",
        "    weight_fn = tf.sigmoid\n",
        "  weights = weight_fn(unnorm_weights)  # [B,m,n]\n",
        "  rep = tf.einsum('bik,bkj->bij', weights, v)  # [B,m,d_v]\n",
        "  return rep\n",
        "\n",
        "\n",
        "def multihead_attention(q, k, v, num_heads=8):\n",
        "  \"\"\"Computes multi-head attention.\n",
        "\n",
        "  Args:\n",
        "    q: queries. tensor of  shape [B,m,d_k].\n",
        "    k: keys. tensor of shape [B,n,d_k].\n",
        "    v: values. tensor of shape [B,n,d_v].\n",
        "    num_heads: number of heads. Should divide d_v.\n",
        "    \n",
        "  Returns:\n",
        "    tensor of shape [B,m,d_v].\n",
        "  \"\"\"\n",
        "  d_k = q.get_shape().as_list()[-1]\n",
        "  d_v = v.get_shape().as_list()[-1]\n",
        "  head_size = d_v / num_heads\n",
        "  key_initializer = tf.random_normal_initializer(stddev=d_k**-0.5)\n",
        "  value_initializer = tf.random_normal_initializer(stddev=d_v**-0.5)\n",
        "  rep = tf.constant(0.0)\n",
        "  for h in range(num_heads):\n",
        "    o = dot_product_attention(\n",
        "        tf.layers.Conv1D(head_size, 1, kernel_initializer=key_initializer,\n",
        "                   name='wq%d' % h, use_bias=False, padding='VALID')(q),\n",
        "        tf.layers.Conv1D(head_size, 1, kernel_initializer=key_initializer,\n",
        "                   name='wk%d' % h, use_bias=False, padding='VALID')(k),\n",
        "        tf.layers.Conv1D(head_size, 1, kernel_initializer=key_initializer,\n",
        "                   name='wv%d' % h, use_bias=False, padding='VALID')(v),\n",
        "        normalise=True)\n",
        "    rep += tf.layers.Conv1D(d_v, 1, kernel_initializer=value_initializer,\n",
        "                      name='wo%d' % h, use_bias=False, padding='VALID')(o)\n",
        "  return rep\n",
        "\n",
        "class Attention(object):\n",
        "  \"\"\"The Attention module.\"\"\"\n",
        "\n",
        "  def __init__(self, rep, output_sizes, att_type, scale=1., normalise=True,\n",
        "               num_heads=8):\n",
        "    \"\"\"Create attention module.\n",
        "\n",
        "    Takes in context inputs, target inputs and\n",
        "    representations of each context input/output pair\n",
        "    to output an aggregated representation of the context data.\n",
        "    Args:\n",
        "      rep: transformation to apply to contexts before computing attention. \n",
        "          One of: ['identity','mlp'].\n",
        "      output_sizes: list of number of hidden units per layer of mlp.\n",
        "          Used only if rep == 'mlp'.\n",
        "      att_type: type of attention. One of the following:\n",
        "          ['uniform','laplace','dot_product','multihead']\n",
        "      scale: scale of attention.\n",
        "      normalise: Boolean determining whether to:\n",
        "          1. apply softmax to weights so that they sum to 1 across context pts or\n",
        "          2. apply custom transformation to have weights in [0,1].\n",
        "      num_heads: number of heads for multihead.\n",
        "    \"\"\"\n",
        "    self._rep = rep\n",
        "    self._output_sizes = output_sizes\n",
        "    self._type = att_type\n",
        "    self._scale = scale\n",
        "    self._normalise = normalise\n",
        "    if self._type == 'multihead':\n",
        "      self._num_heads = num_heads\n",
        "\n",
        "  def __call__(self, x1, x2, r):\n",
        "    \"\"\"Apply attention to create aggregated representation of r.\n",
        "\n",
        "    Args:\n",
        "      x1: tensor of shape [B,n1,d_x].\n",
        "      x2: tensor of shape [B,n2,d_x].\n",
        "      r: tensor of shape [B,n1,d].\n",
        "      \n",
        "    Returns:\n",
        "      tensor of shape [B,n2,d]\n",
        "\n",
        "    Raises:\n",
        "      NameError: The argument for rep/type was invalid.\n",
        "    \"\"\"\n",
        "    if self._rep == 'identity':\n",
        "      k, q = (x1, x2)\n",
        "    elif self._rep == 'mlp':\n",
        "      # Pass through MLP\n",
        "      k = batch_mlp(x1, self._output_sizes, \"attention\")\n",
        "      q = batch_mlp(x2, self._output_sizes, \"attention\")\n",
        "    else:\n",
        "      raise NameError(\"'rep' not among ['identity','mlp']\")\n",
        "\n",
        "    if self._type == 'uniform':\n",
        "      rep = uniform_attention(q, r)\n",
        "    elif self._type == 'laplace':\n",
        "      rep = laplace_attention(q, k, r, self._scale, self._normalise)\n",
        "    elif self._type == 'dot_product':\n",
        "      rep = dot_product_attention(q, k, r, self._normalise)\n",
        "    elif self._type == 'multihead':\n",
        "      rep = multihead_attention(q, k, r, self._num_heads)\n",
        "    else:\n",
        "      raise NameError((\"'att_type' not among ['uniform','laplace','dot_product'\"\n",
        "                       \",'multihead']\"))\n",
        "\n",
        "    return rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLY6KN9D2AOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Normalization_old(data):\n",
        "  data_f = data.astype(float)\n",
        "  data_mean = np.mean(data_f, axis=0, keepdims=True)\n",
        "  data_n = data_f - data_mean\n",
        "  data_range = np.max(np.abs(data_n), axis=0, keepdims=True)\n",
        "  data_n = data_n / data_range\n",
        "  \n",
        "  return data_n\n",
        "\n",
        "def datawrap(data_x, data_y, batch_size):\n",
        "  num_target = 0\n",
        "  num_context = 50\n",
        "  batch_num = int(data_x.shape[0]/batch_size)\n",
        "  batch_datax = []\n",
        "  batch_datay = []\n",
        "  for i in range(batch_num):\n",
        "    locations = np.random.choice(data_x.shape[0],\n",
        "                                 size=batch_size,\n",
        "                                 replace=False)\n",
        "    tmp = data_x[locations,:]\n",
        "    batch_datax.append(tmp)\n",
        "    tmp = data_y[locations,:]\n",
        "    batch_datay.append(tmp)\n",
        "    #finish batching\n",
        "  context_x = np.array(batch_datax)[:,:num_context,:]\n",
        "  context_y = np.array(batch_datay)[:,:num_context,:]\n",
        "  target_x = np.array(batch_datax)[:,:num_context+num_target,:]\n",
        "  target_y = np.array(batch_datay)[:,:num_context+num_target,:]\n",
        "  \n",
        "    #convert to tensor TF from np array\n",
        "  context_x = tf.convert_to_tensor(context_x, np.float32)\n",
        "  context_y = tf.convert_to_tensor(context_y, np.float32)\n",
        "  target_x = tf.convert_to_tensor(target_x, np.float32)\n",
        "  target_y = tf.convert_to_tensor(target_y, np.float32)\n",
        "  \n",
        "  query = ((context_x, context_y), target_x)\n",
        "  num_total_points = num_context+num_target\n",
        "  num_context_points = num_context\n",
        "  return query, target_y, num_total_points, num_context_points\n",
        "\n",
        "def testdatawrap(data_x, data_y, batch_size):\n",
        "  num_target = 50\n",
        "  ratio_ct = 0.7\n",
        "  num_context = int(ratio_ct * batch_size)\n",
        "  batch_num = int(data_x.shape[0]/batch_size)\n",
        "  batch_datax = []\n",
        "  batch_datay = []\n",
        "  for i in range(batch_num):\n",
        "    locations = np.random.choice(data_x.shape[0],\n",
        "                                 size=batch_size,\n",
        "                                 replace=False)\n",
        "    tmp = data_x[locations,:]\n",
        "    batch_datax.append(tmp)\n",
        "    tmp = data_y[locations,:]\n",
        "    batch_datay.append(tmp)\n",
        "    #finish batching\n",
        "  context_x = np.array(batch_datax)[:,:num_context,:]#context is belong to target\n",
        "  context_y = np.array(batch_datay)[:,:num_context,:]\n",
        "  target_x = np.array(batch_datax)#x values\n",
        "  target_y = np.array(batch_datay)#y values\n",
        "  \n",
        "  #convert to tensor TF from np array\n",
        "  context_x = tf.convert_to_tensor(context_x, np.float32)\n",
        "  context_y = tf.convert_to_tensor(context_y, np.float32)\n",
        "  target_x = tf.convert_to_tensor(target_x, np.float32)\n",
        "  target_y = tf.convert_to_tensor(target_y, np.float32)\n",
        "  \n",
        "  query = ((context_x, context_y), target_x)\n",
        "  num_total_points = batch_size \n",
        "  num_context_points = num_context\n",
        "  return query, target_y, num_total_points, num_context_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLCV6Bc42AO0",
        "colab_type": "text"
      },
      "source": [
        "# Data Selector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpnuTB-w2AO1",
        "colab_type": "code",
        "colab": {},
        "outputId": "42a1a5a8-4809-4379-ba3d-324bfb45a7ef"
      },
      "source": [
        "filename = \"/home/yufeng/projects/rrg-kyi/yufeng/gaia/data/refcat_yufengzhu.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "gaia_selected = df.loc[(df['dplx'] <= 0.1) \n",
        "                       & (df['plx'] <= 5) & (df['plx'] > 0)]\n",
        "print(gaia_selected.shape)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['Gaia'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['BP'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['RP'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['g'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['i'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['r'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['z'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66619, 45)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/yufeng/jupyter_py3/lib/python3.6/site-packages/pandas/core/frame.py:4097: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kpmWj-k2AO7",
        "colab_type": "code",
        "colab": {},
        "outputId": "434a51aa-8f74-413b-8ad4-37012f3dbd96"
      },
      "source": [
        "#gaia_selected = Normalization_old(np.array(gaia_selected))\n",
        "gaia_selected = np.array(gaia_selected)\n",
        "gaia_selected = pd.DataFrame(gaia_selected)\n",
        "\n",
        "g_mag = gaia_selected.loc[:, [1, 2, 9, 3]]\n",
        "#g_mag = g_mag.rename(columns={'Gaia':\"mag\"})\n",
        "g_mag = g_mag.dropna()\n",
        "\n",
        "bp_mag = gaia_selected.loc[:, [1, 2, 11, 3]]\n",
        "#bp_mag = bp_mag.rename(columns={'BP':\"mag\"})\n",
        "bp_mag = bp_mag.dropna()\n",
        "\n",
        "rp_mag = gaia_selected.loc[:, [1, 2, 13, 3]]\n",
        "#rp_mag = rp_mag.rename(columns={'RP':\"mag\"})\n",
        "rp_mag = rp_mag.dropna()\n",
        "\n",
        "i_mag = gaia_selected.loc[:, [1, 2,30, 3]]\n",
        "#i_mag = i_mag.rename(columns={'i':\"mag\"})\n",
        "i_mag = i_mag.dropna()\n",
        "\n",
        "gg_mag = gaia_selected.loc[:, [1, 2,22, 3]]\n",
        "#gg_mag = gg_mag.rename(columns={'g':\"mag\"})\n",
        "gg_mag = gg_mag.dropna()\n",
        "\n",
        "r_mag = gaia_selected.loc[:, [1, 2,26, 3]]\n",
        "#r_mag = r_mag.rename(columns={'r':\"mag\"})\n",
        "r_mag = r_mag.dropna()\n",
        "\n",
        "g_mag ['wavelength'] = -0.160976190476 #5857.6\n",
        "bp_mag ['wavelength'] = -0.354516666667 #5044.4\n",
        "rp_mag ['wavelength'] = 0.275911904762 #7692.2\n",
        "gg_mag['wavelength'] = -0.410111904762 #4810.9\n",
        "r_mag['wavelength'] = -0.0897785714286 #6156.3\n",
        "i_mag['wavelength'] = 0.231030952381 #7503.7\n",
        "#z_mag['wavelength'] =  0.508364285714 #8668.5\n",
        "\n",
        "g_mag = np.array(g_mag)\n",
        "bp_mag = np.array(bp_mag)\n",
        "rp_mag = np.array(rp_mag)\n",
        "#mag norm\n",
        "g_mag[:,2] = (g_mag[:,2]-16)/17\n",
        "bp_mag[:,2] = (bp_mag[:,2]-16)/17\n",
        "rp_mag[:,2] = (rp_mag[:,2]-16)/17\n",
        "# ra norm\n",
        "g_mag[:,0] = (g_mag[:,0]-3)/6\n",
        "bp_mag[:,0] = (bp_mag[:,0]-3)/6\n",
        "rp_mag[:,0] = (rp_mag[:,0]-3)/6\n",
        "# dec norm\n",
        "g_mag[:,1] = (g_mag[:,1]-0.008)/2.5\n",
        "bp_mag[:,1] = (bp_mag[:,1]-0.008)/2.5\n",
        "rp_mag[:,1] = (rp_mag[:,1]-0.008)/2.5\n",
        "\n",
        "\n",
        "gg_mag = np.array(gg_mag)\n",
        "r_mag = np.array(r_mag)\n",
        "i_mag = np.array(i_mag)\n",
        "\n",
        "gg_mag[:,2] = (gg_mag[:,2]-16)/17\n",
        "r_mag[:,2] = (r_mag[:,2]-16)/17\n",
        "i_mag[:,2] = (i_mag[:,2]-16)/17\n",
        "\n",
        "# ra norm\n",
        "gg_mag[:,0] = (gg_mag[:,0]-3)/6\n",
        "r_mag[:,0] = (r_mag[:,0]-3)/6\n",
        "i_mag[:,0] = (i_mag[:,0]-3)/6\n",
        "# dec norm\n",
        "gg_mag[:,1] = (gg_mag[:,1]-0.008)/2.5\n",
        "r_mag[:,1] = (r_mag[:,1]-0.008)/2.5\n",
        "i_mag[:,1] = (i_mag[:,1]-0.008)/2.5\n",
        "\n",
        "\n",
        "all_df = []\n",
        "for i in range(g_mag.shape[0]):\n",
        "    row = []\n",
        "    for j in range(g_mag.shape[1]):\n",
        "        #tmp = [g_mag[i][j]]+[bp_mag[i][j]]+[rp_mag[i][j]]\n",
        "        #tmp = [gg_mag[i][j]]+[r_mag[i][j]]+[rp_mag[i][j]]\n",
        "        tmp = [bp_mag[i][j]]+[g_mag[i][j]]+[i_mag[i][j]]\n",
        "        #tmp = [bp_mag[i][j]]\n",
        "        #tmp = [rp_mag[i][j]]+[r_mag[i][j]]+[gg_mag[i][j]]\n",
        "        #tmp = [rp_mag[i][j]] + [gg_mag[i][j]] + [r_mag[i][j]]\n",
        "        row.append(tmp)\n",
        "    all_df.append(row)\n",
        "\n",
        "all_df = np.array(all_df)\n",
        "\n",
        "y_df = all_df[:,3,0]\n",
        "x_df = all_df[:,[0,1,2,4],:]\n",
        "\n",
        "x_df = np.reshape(x_df,(x_df.shape[0],x_df.shape[1], x_df.shape[2], 1))\n",
        "y_df = np.reshape(y_df,(-1, 1))\n",
        "\n",
        "y_df = (y_df-1.25)/5\n",
        "\n",
        "ratio = 0.95 #the ratio is train/all \n",
        "msk = np.random.rand(len(x_df)) < ratio\n",
        "train_x = x_df[msk]\n",
        "train_y = y_df[msk]\n",
        "test_x = x_df[~msk]\n",
        "test_y = y_df[~msk]\n",
        "\n",
        "train_norm_x = np.array(train_x)\n",
        "test_norm_x = np.array(test_x)\n",
        "\n",
        "test_norm_y = np.array(test_y)\n",
        "train_norm_y =np.array(train_y)\n",
        "\n",
        "train_norm_x = np.array(train_norm_x).astype(float)\n",
        "train_norm_y = np.array(train_norm_y).astype(float)\n",
        "test_norm_x = np.array(test_norm_x).astype(float)\n",
        "test_norm_y = np.array(test_norm_y).astype(float)\n",
        "\n",
        "print(train_norm_x.shape)\n",
        "\n",
        "test_norm_x = pan_test_norm_x\n",
        "test_norm_y = pan_test_norm_y\n",
        "\n",
        "print(test_norm_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(63170, 4, 3, 1)\n",
            "(6674, 4, 3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axbSnV-O2AO_",
        "colab_type": "code",
        "colab": {},
        "outputId": "f7cb722a-3b06-443a-f251-3ed33590d0c6"
      },
      "source": [
        "g_mag = gaia_selected.loc[:, [1, 2, 9, 3]]\n",
        "#g_mag = g_mag.rename(columns={'Gaia':\"mag\"})\n",
        "g_mag = g_mag.dropna()\n",
        "\n",
        "bp_mag = gaia_selected.loc[:, [1, 2, 11, 3]]\n",
        "#bp_mag = bp_mag.rename(columns={'BP':\"mag\"})\n",
        "bp_mag = bp_mag.dropna()\n",
        "\n",
        "rp_mag = gaia_selected.loc[:, [1, 2, 13, 3]]\n",
        "#rp_mag = rp_mag.rename(columns={'RP':\"mag\"})\n",
        "rp_mag = rp_mag.dropna()\n",
        "\n",
        "i_mag = gaia_selected.loc[:, [1, 2,30, 3]]\n",
        "#i_mag = i_mag.rename(columns={'i':\"mag\"})\n",
        "i_mag = i_mag.dropna()\n",
        "\n",
        "gg_mag = gaia_selected.loc[:, [1, 2,22, 3]]\n",
        "#gg_mag = gg_mag.rename(columns={'g':\"mag\"})\n",
        "gg_mag = gg_mag.dropna()\n",
        "\n",
        "r_mag = gaia_selected.loc[:, [1, 2,26, 3]]\n",
        "#r_mag = r_mag.rename(columns={'r':\"mag\"})\n",
        "r_mag = r_mag.dropna()\n",
        "\n",
        "\n",
        "g_mag ['wavelength'] = -0.160976190476 #5857.6\n",
        "bp_mag ['wavelength'] = -0.354516666667 #5044.4\n",
        "rp_mag ['wavelength'] = 0.275911904762 #7692.2\n",
        "gg_mag['wavelength'] = -0.410111904762 #4810.9\n",
        "r_mag['wavelength'] = -0.0897785714286 #6156.3\n",
        "i_mag['wavelength'] = 0.231030952381 #7503.7\n",
        "#z_mag['wavelength'] =  0.508364285714 #8668.5\n",
        "\n",
        "g_mag = np.array(g_mag)\n",
        "bp_mag = np.array(bp_mag)\n",
        "rp_mag = np.array(rp_mag)\n",
        "#mag norm\n",
        "g_mag[:,2] = (g_mag[:,2]-16)/17\n",
        "bp_mag[:,2] = (bp_mag[:,2]-16)/17\n",
        "rp_mag[:,2] = (rp_mag[:,2]-16)/17\n",
        "# ra norm\n",
        "g_mag[:,0] = (g_mag[:,0]-3)/6\n",
        "bp_mag[:,0] = (bp_mag[:,0]-3)/6\n",
        "rp_mag[:,0] = (rp_mag[:,0]-3)/6\n",
        "# dec norm\n",
        "g_mag[:,1] = (g_mag[:,1]-0.008)/2.5\n",
        "bp_mag[:,1] = (bp_mag[:,1]-0.008)/2.5\n",
        "rp_mag[:,1] = (rp_mag[:,1]-0.008)/2.5\n",
        "\n",
        "gg_mag = np.array(gg_mag)\n",
        "r_mag = np.array(r_mag)\n",
        "i_mag = np.array(i_mag)\n",
        "\n",
        "gg_mag[:,2] = (gg_mag[:,2]-16)/17\n",
        "r_mag[:,2] = (r_mag[:,2]-16)/17\n",
        "i_mag[:,2] = (i_mag[:,2]-16)/17\n",
        "\n",
        "# ra norm\n",
        "gg_mag[:,0] = (gg_mag[:,0]-3)/6\n",
        "r_mag[:,0] = (r_mag[:,0]-3)/6\n",
        "i_mag[:,0] = (i_mag[:,0]-3)/6\n",
        "# dec norm\n",
        "gg_mag[:,1] = (gg_mag[:,1]-0.008)/2.5\n",
        "r_mag[:,1] = (r_mag[:,1]-0.008)/2.5\n",
        "i_mag[:,1] = (i_mag[:,1]-0.008)/2.5\n",
        "\n",
        "all_df = []\n",
        "for i in range(g_mag.shape[0]):\n",
        "    row = []\n",
        "    for j in range(g_mag.shape[1]):\n",
        "        #tmp = [gg_mag[i][j]]+[r_mag[i][j]]+[i_mag[i][j]]\n",
        "        #tmp = [gg_mag[i][j]]+[i_mag[i][j]]+[r_mag[i][j]]\n",
        "        #tmp = [bp_mag[i][j]]+[g_mag[i][j]]+[i_mag[i][j]]\n",
        "        tmp = [bp_mag[i][j]]+[g_mag[i][j]] + [bp_mag[i][j]]\n",
        "        #tmp = [gg_mag[i][j]] + [gg_mag[i][j]] + [gg_mag[i][j]]\n",
        "        #tmp = [gg_mag[i][j]]+[r_mag[i][j]]\n",
        "        row.append(tmp)\n",
        "    all_df.append(row)\n",
        "\n",
        "all_df = np.array(all_df)\n",
        "\n",
        "y_df = all_df[:,3,0]\n",
        "x_df = all_df[:,[0,1,2,4],:]\n",
        "\n",
        "x_df = np.reshape(x_df,(x_df.shape[0],x_df.shape[1], x_df.shape[2], 1))\n",
        "y_df = np.reshape(y_df,(-1, 1))\n",
        "\n",
        "y_df = (y_df-1.25)/5\n",
        "\n",
        "ratio = 0.9 #the ratio is train/all \n",
        "msk = np.random.rand(len(x_df)) < ratio\n",
        "train_x = x_df[msk]\n",
        "train_y = y_df[msk]\n",
        "test_x = x_df[~msk]\n",
        "test_y = y_df[~msk]\n",
        "\n",
        "train_norm_x = np.array(train_x)\n",
        "test_norm_x = np.array(test_x)\n",
        "\n",
        "test_norm_y = np.array(test_y)\n",
        "train_norm_y =np.array(train_y)\n",
        "\n",
        "train_norm_x = np.array(train_norm_x).astype(float)\n",
        "train_norm_y = np.array(train_norm_y).astype(float)\n",
        "test_norm_x = np.array(test_norm_x).astype(float)\n",
        "test_norm_y = np.array(test_norm_y).astype(float)\n",
        "\n",
        "print(train_norm_x.shape)\n",
        "print(test_norm_x.shape)\n",
        "pan_test_norm_x = test_norm_x\n",
        "pan_test_norm_y = test_norm_y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59799, 4, 3, 1)\n",
            "(6674, 4, 3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByrR5kvS2APB",
        "colab_type": "text"
      },
      "source": [
        "# all in one row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDXmw2bZ2APD",
        "colab_type": "code",
        "colab": {},
        "outputId": "6d41ea26-f5b4-463f-9104-25dc6720984b"
      },
      "source": [
        "filename = \"/home/yufeng/projects/rrg-kyi/yufeng/gaia/data/refcat_yufengzhu.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "gaia_selected = df.loc[(df['dplx'] <= 0.2) \n",
        "                       & (df['plx'] <= 5) & (df['plx'] > 0)]\n",
        "\n",
        "new_df = gaia_selected.loc[:, ['RA', 'Dec','Gaia','BP','RP','g','i','r','z','plx']]\n",
        "\n",
        "x_df = new_df.loc[:,['RA', 'Dec','Gaia','BP','RP','g','i','r','z']]\n",
        "y_df = new_df.loc[:,['plx']]\n",
        "\n",
        "indexNames = x_df[x_df['Gaia'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['BP'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['RP'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['g'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['i'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['r'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['z'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "x_df = new_df.loc[:,['RA', 'Dec','g','r','RP']]\n",
        "y_df = new_df.loc[:,['plx']]\n",
        "\n",
        "#x_df ['g_wavelength'] = -0.160976190476 #5857.6\n",
        "#x_df ['bp_wavelength'] = -0.354516666667 #5044.4\n",
        "\n",
        "x_df ['gg_wavelength'] = -0.410111904762 #4810.9\n",
        "x_df ['r_wavelength'] = -0.0897785714286 #6156.3\n",
        "x_df ['rp_wavelength'] = 0.275911904762 #7692.2\n",
        "#x_df ['i_wavelength'] = 0.231030952381 #7503.7\n",
        "\n",
        "x_df['RA'] = (x_df['RA']-3)/60\n",
        "x_df['Dec'] = (x_df['Dec']-0.008)/2.5\n",
        "x_df['g'] = (x_df['g']-16)/17\n",
        "x_df['r'] = (x_df['r']-16)/17\n",
        "x_df['RP'] = (x_df['RP']-16)/17\n",
        "\n",
        "y_df['plx'] = (y_df['plx']-1.25)/5\n",
        "\n",
        "ratio = 0.9 #the ratio is train/all \n",
        "msk = np.random.rand(len(x_df)) < ratio\n",
        "train_x = x_df[msk]\n",
        "train_y = y_df[msk]\n",
        "test_x = x_df[~msk]\n",
        "test_y = y_df[~msk]\n",
        "\n",
        "train_norm_x = np.array(train_x)\n",
        "test_norm_x = np.array(test_x)\n",
        "\n",
        "test_norm_y = np.array(test_y)\n",
        "train_norm_y =np.array(train_y)\n",
        "\n",
        "train_norm_x = np.array(train_norm_x).astype(float)\n",
        "train_norm_y = np.array(train_norm_y).astype(float)\n",
        "test_norm_x = np.array(test_norm_x).astype(float)\n",
        "test_norm_y = np.array(test_norm_y).astype(float)\n",
        "\n",
        "print(train_norm_x.shape)\n",
        "print(test_norm_x.shape)\n",
        "\n",
        "test_norm_x = pan_test_norm_x\n",
        "test_norm_y = pan_test_norm_y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(103900, 8)\n",
            "(11513, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qj3uJM2APG",
        "colab_type": "code",
        "colab": {},
        "outputId": "872fb346-db31-4716-f329-0106977652e8"
      },
      "source": [
        "filename = \"/home/yufeng/projects/rrg-kyi/yufeng/gaia/data/refcat_yufengzhu.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "gaia_selected = df.loc[(df['dplx'] <= 0.2) \n",
        "                       & (df['plx'] <= 5) & (df['plx'] > 0)]\n",
        "\n",
        "new_df = gaia_selected.loc[:, ['RA', 'Dec','Gaia','BP','RP','g','i','r','z','plx']]\n",
        "\n",
        "x_df = new_df.loc[:,['RA', 'Dec','Gaia','BP','RP','g','i','r','z']]\n",
        "y_df = new_df.loc[:,['plx']]\n",
        "\n",
        "indexNames = x_df[x_df['Gaia'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['BP'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['RP'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['g'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['i'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['r'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = x_df[x_df['z'] <= 0.].index\n",
        "x_df.drop(indexNames, inplace=True)\n",
        "y_df.drop(indexNames, inplace=True)\n",
        "\n",
        "x_df = new_df.loc[:,['RA', 'Dec','BP','Gaia','i']]\n",
        "y_df = new_df.loc[:,['plx']]\n",
        "\n",
        "\n",
        "x_df ['bp_wavelength'] = -0.354516666667 #5044.4\n",
        "x_df ['g_wavelength'] = -0.160976190476 #5857.6\n",
        "#x_df ['rp_wavelength'] = 0.275911904762 #7692.2\n",
        "#x_df ['gg_wavelength'] = -0.410111904762 #4810.9\n",
        "#x_df ['r_wavelength'] = -0.0897785714286 #6156.3\n",
        "x_df ['i_wavelength'] = 0.231030952381 #7503.7\n",
        "\n",
        "x_df['RA'] = (x_df['RA']-3)/60\n",
        "x_df['Dec'] = (x_df['Dec']-0.008)/2.5\n",
        "x_df['BP'] = (x_df['BP']-16)/17\n",
        "x_df['Gaia'] = (x_df['Gaia']-16)/17\n",
        "x_df['i'] = (x_df['i']-16)/17\n",
        "\n",
        "y_df['plx'] = (y_df['plx']-1.25)/5\n",
        "\n",
        "ratio = 0.9 #the ratio is train/all \n",
        "msk = np.random.rand(len(x_df)) < ratio\n",
        "train_x = x_df[msk]\n",
        "train_y = y_df[msk]\n",
        "test_x = x_df[~msk]\n",
        "test_y = y_df[~msk]\n",
        "\n",
        "train_norm_x = np.array(train_x)\n",
        "test_norm_x = np.array(test_x)\n",
        "\n",
        "test_norm_y = np.array(test_y)\n",
        "train_norm_y =np.array(train_y)\n",
        "\n",
        "train_norm_x = np.array(train_norm_x).astype(float)\n",
        "train_norm_y = np.array(train_norm_y).astype(float)\n",
        "test_norm_x = np.array(test_norm_x).astype(float)\n",
        "test_norm_y = np.array(test_norm_y).astype(float)\n",
        "\n",
        "print(train_norm_x.shape)\n",
        "print(test_norm_x.shape)\n",
        "\n",
        "pan_test_norm_x = test_norm_x \n",
        "pan_test_norm_y = test_norm_y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(103964, 8)\n",
            "(11449, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Wo-Ub82APJ",
        "colab_type": "text"
      },
      "source": [
        "# dim = {Ra, Dec, Mag, Wav}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUtRj1Kv2APL",
        "colab_type": "code",
        "colab": {},
        "outputId": "24bd717a-2c1c-423f-e787-b8f34c21c4d1"
      },
      "source": [
        "filename = \"/home/yufeng/projects/rrg-kyi/yufeng/gaia/data/refcat_yufengzhu.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "gaia_selected = df.loc[(df['dplx'] <= 0.1) \n",
        "                       & (df['plx'] <= 5) & (df['plx'] > 0)]\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['Gaia'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['BP'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['RP'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['g'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['i'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['r'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['z'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "#gaia_selected = Normalization_old(np.array(gaia_selected))\n",
        "gaia_selected = np.array(gaia_selected)\n",
        "gaia_selected = pd.DataFrame(gaia_selected)\n",
        "\n",
        "g_mag = gaia_selected.loc[:, [1, 2, 9, 3]]\n",
        "#g_mag = g_mag.rename(columns={'Gaia':\"mag\"})\n",
        "g_mag = g_mag.dropna()\n",
        "\n",
        "bp_mag = gaia_selected.loc[:, [1, 2, 11, 3]]\n",
        "#bp_mag = bp_mag.rename(columns={'BP':\"mag\"})\n",
        "bp_mag = bp_mag.dropna()\n",
        "\n",
        "rp_mag = gaia_selected.loc[:, [1, 2, 13, 3]]\n",
        "#rp_mag = rp_mag.rename(columns={'RP':\"mag\"})\n",
        "rp_mag = rp_mag.dropna()\n",
        "\n",
        "i_mag = gaia_selected.loc[:, [1, 2,30, 3]]\n",
        "#i_mag = i_mag.rename(columns={'i':\"mag\"})\n",
        "i_mag = i_mag.dropna()\n",
        "\n",
        "gg_mag = gaia_selected.loc[:, [1, 2,22, 3]]\n",
        "#gg_mag = gg_mag.rename(columns={'g':\"mag\"})\n",
        "gg_mag = gg_mag.dropna()\n",
        "\n",
        "r_mag = gaia_selected.loc[:, [1, 2,26, 3]]\n",
        "#r_mag = r_mag.rename(columns={'r':\"mag\"})\n",
        "r_mag = r_mag.dropna()\n",
        "\n",
        "z_mag = gaia_selected.loc[:, [1, 2,26, 3]]\n",
        "#r_mag = r_mag.rename(columns={'r':\"mag\"})\n",
        "z_mag = z_mag.dropna()\n",
        "\n",
        "g_mag ['wavelength'] = -0.160976190476 #5857.6\n",
        "bp_mag ['wavelength'] = -0.354516666667 #5044.4\n",
        "rp_mag ['wavelength'] = 0.275911904762 #7692.2\n",
        "gg_mag['wavelength'] = -0.410111904762 #4810.9\n",
        "r_mag['wavelength'] = -0.0897785714286 #6156.3\n",
        "i_mag['wavelength'] = 0.231030952381 #7503.7\n",
        "z_mag['wavelength'] =  0.508364285714 #8668.5\n",
        "\n",
        "g_mag = np.array(g_mag)\n",
        "bp_mag = np.array(bp_mag)\n",
        "rp_mag = np.array(rp_mag)\n",
        "z_mag = np.array(z_mag)\n",
        "#mag norm\n",
        "g_mag[:,2] = (g_mag[:,2]-16)/17\n",
        "bp_mag[:,2] = (bp_mag[:,2]-16)/17\n",
        "rp_mag[:,2] = (rp_mag[:,2]-16)/17\n",
        "z_mag[:,2] = (z_mag[:,2]-16)/17\n",
        "# ra norm\n",
        "g_mag[:,0] = (g_mag[:,0]-3)/60\n",
        "bp_mag[:,0] = (bp_mag[:,0]-3)/60\n",
        "rp_mag[:,0] = (rp_mag[:,0]-3)/60\n",
        "z_mag[:,0] = (z_mag[:,0]-3)/60\n",
        "# dec norm\n",
        "g_mag[:,1] = (g_mag[:,1]-0.008)/2.5\n",
        "bp_mag[:,1] = (bp_mag[:,1]-0.008)/2.5\n",
        "rp_mag[:,1] = (rp_mag[:,1]-0.008)/2.5\n",
        "z_mag[:,1] = (z_mag[:,1]-0.008)/2.5\n",
        "\n",
        "\n",
        "gg_mag = np.array(gg_mag)\n",
        "r_mag = np.array(r_mag)\n",
        "i_mag = np.array(i_mag)\n",
        "\n",
        "gg_mag[:,2] = (gg_mag[:,2]-16)/17\n",
        "r_mag[:,2] = (r_mag[:,2]-16)/17\n",
        "i_mag[:,2] = (i_mag[:,2]-16)/17\n",
        "\n",
        "# ra norm\n",
        "gg_mag[:,0] = (gg_mag[:,0]-3)/60\n",
        "r_mag[:,0] = (r_mag[:,0]-3)/60\n",
        "i_mag[:,0] = (i_mag[:,0]-3)/60\n",
        "# dec norm\n",
        "gg_mag[:,1] = (gg_mag[:,1]-0.008)/2.5\n",
        "r_mag[:,1] = (r_mag[:,1]-0.008)/2.5\n",
        "i_mag[:,1] = (i_mag[:,1]-0.008)/2.5\n",
        "\n",
        "all_df = []\n",
        "\n",
        "for i in range(g_mag.shape[0]):\n",
        "    row = []\n",
        "    row.append(g_mag[i])\n",
        "    row.append(gg_mag[i])   \n",
        "    row.append(i_mag[i])    \n",
        "    row.append(bp_mag[i])\n",
        "    row.append(r_mag[i])\n",
        "    row.append(rp_mag[i])\n",
        "    row.append(z_mag[i])\n",
        "    all_df.append(row)\n",
        "\n",
        "all_df = np.array(all_df)\n",
        "\n",
        "x_df = all_df[:,:,[0,1,2,4]]\n",
        "y_df = all_df[:,0,[3]]\n",
        "\n",
        "# norm y\n",
        "y_df = (y_df-1.25)/5\n",
        "\n",
        "x_df = np.reshape(x_df, (x_df.shape[0], 1, x_df.shape[1], x_df.shape[2]))\n",
        "\n",
        "ratio = 0.9 #the ratio is train/all \n",
        "msk = np.random.rand(len(x_df)) < ratio\n",
        "train_x = x_df[msk]\n",
        "train_y = y_df[msk]\n",
        "test_x = x_df[~msk]\n",
        "test_y = y_df[~msk]\n",
        "\n",
        "train_norm_x = np.array(train_x)\n",
        "test_norm_x = np.array(test_x)\n",
        "\n",
        "test_norm_y = np.array(test_y)\n",
        "train_norm_y = np.array(train_y)\n",
        "\n",
        "train_norm_x = np.array(train_norm_x).astype(float)\n",
        "train_norm_y = np.array(train_norm_y).astype(float)\n",
        "test_norm_x = np.array(test_norm_x).astype(float)\n",
        "test_norm_y = np.array(test_norm_y).astype(float)\n",
        "\n",
        "print(train_norm_x.shape)\n",
        "print(test_norm_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59843, 1, 7, 4)\n",
            "(6630, 1, 7, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDchuSB62APN",
        "colab_type": "code",
        "colab": {},
        "outputId": "7628c78f-90a4-4583-85d6-1de8567c621e"
      },
      "source": [
        "filename = \"/home/yufeng/projects/rrg-kyi/yufeng/gaia/data/refcat_yufengzhu.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "gaia_selected = df.loc[(df['dplx'] <= 0.1) \n",
        "                       & (df['plx'] <= 5) & (df['plx'] > 0)]\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['Gaia'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['BP'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['RP'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['g'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['i'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['r'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "\n",
        "indexNames = gaia_selected[gaia_selected['z'] <= 0.].index\n",
        "gaia_selected.drop(indexNames, inplace=True)\n",
        "\n",
        "#gaia_selected = Normalization_old(np.array(gaia_selected))\n",
        "gaia_selected = np.array(gaia_selected)\n",
        "gaia_selected = pd.DataFrame(gaia_selected)\n",
        "\n",
        "g_mag = gaia_selected.loc[:, [1, 2, 9, 3]]\n",
        "#g_mag = g_mag.rename(columns={'Gaia':\"mag\"})\n",
        "g_mag = g_mag.dropna()\n",
        "\n",
        "bp_mag = gaia_selected.loc[:, [1, 2, 11, 3]]\n",
        "#bp_mag = bp_mag.rename(columns={'BP':\"mag\"})\n",
        "bp_mag = bp_mag.dropna()\n",
        "\n",
        "rp_mag = gaia_selected.loc[:, [1, 2, 13, 3]]\n",
        "#rp_mag = rp_mag.rename(columns={'RP':\"mag\"})\n",
        "rp_mag = rp_mag.dropna()\n",
        "\n",
        "i_mag = gaia_selected.loc[:, [1, 2,30, 3]]\n",
        "#i_mag = i_mag.rename(columns={'i':\"mag\"})\n",
        "i_mag = i_mag.dropna()\n",
        "\n",
        "gg_mag = gaia_selected.loc[:, [1, 2,22, 3]]\n",
        "#gg_mag = gg_mag.rename(columns={'g':\"mag\"})\n",
        "gg_mag = gg_mag.dropna()\n",
        "\n",
        "r_mag = gaia_selected.loc[:, [1, 2,26, 3]]\n",
        "#r_mag = r_mag.rename(columns={'r':\"mag\"})\n",
        "r_mag = r_mag.dropna()\n",
        "\n",
        "g_mag ['wavelength'] = -0.160976190476 #5857.6\n",
        "bp_mag ['wavelength'] = -0.354516666667 #5044.4\n",
        "rp_mag ['wavelength'] = 0.275911904762 #7692.2\n",
        "gg_mag['wavelength'] = -0.410111904762 #4810.9\n",
        "r_mag['wavelength'] = -0.0897785714286 #6156.3\n",
        "i_mag['wavelength'] = 0.231030952381 #7503.7\n",
        "#z_mag['wavelength'] =  0.508364285714 #8668.5\n",
        "\n",
        "g_mag = np.array(g_mag)\n",
        "bp_mag = np.array(bp_mag)\n",
        "rp_mag = np.array(rp_mag)\n",
        "#mag norm\n",
        "g_mag[:,2] = (g_mag[:,2]-16)/17\n",
        "bp_mag[:,2] = (bp_mag[:,2]-16)/17\n",
        "rp_mag[:,2] = (rp_mag[:,2]-16)/17\n",
        "# ra norm\n",
        "g_mag[:,0] = (g_mag[:,0]-3)/60\n",
        "bp_mag[:,0] = (bp_mag[:,0]-3)/60\n",
        "rp_mag[:,0] = (rp_mag[:,0]-3)/60\n",
        "# dec norm\n",
        "g_mag[:,1] = (g_mag[:,1]-0.008)/2.5\n",
        "bp_mag[:,1] = (bp_mag[:,1]-0.008)/2.5\n",
        "rp_mag[:,1] = (rp_mag[:,1]-0.008)/2.5\n",
        "\n",
        "\n",
        "gg_mag = np.array(gg_mag)\n",
        "r_mag = np.array(r_mag)\n",
        "i_mag = np.array(i_mag)\n",
        "\n",
        "gg_mag[:,2] = (gg_mag[:,2]-16)/17\n",
        "r_mag[:,2] = (r_mag[:,2]-16)/17\n",
        "i_mag[:,2] = (i_mag[:,2]-16)/17\n",
        "\n",
        "# ra norm\n",
        "gg_mag[:,0] = (gg_mag[:,0]-3)/60\n",
        "r_mag[:,0] = (r_mag[:,0]-3)/60\n",
        "i_mag[:,0] = (i_mag[:,0]-3)/60\n",
        "# dec norm\n",
        "gg_mag[:,1] = (gg_mag[:,1]-0.008)/2.5\n",
        "r_mag[:,1] = (r_mag[:,1]-0.008)/2.5\n",
        "i_mag[:,1] = (i_mag[:,1]-0.008)/2.5\n",
        "\n",
        "all_df = []\n",
        "\n",
        "for i in range(g_mag.shape[0]):\n",
        "    row = []\n",
        "    row.append(r_mag[i])\n",
        "    row.append(gg_mag[i])\n",
        "    row.append(i_mag[i])\n",
        "    all_df.append(row)\n",
        "\n",
        "all_df = np.array(all_df)\n",
        "\n",
        "x_df = all_df[:,:,[0,1,2,4]]\n",
        "y_df = all_df[:,0,[3]]\n",
        "\n",
        "# norm y\n",
        "y_df = (y_df-1.25)/5\n",
        "\n",
        "x_df = np.reshape(x_df, (x_df.shape[0], 1, x_df.shape[1], x_df.shape[2]))\n",
        "\n",
        "ratio = 0.9 #the ratio is train/all \n",
        "msk = np.random.rand(len(x_df)) < ratio\n",
        "train_x = x_df[msk]\n",
        "train_y = y_df[msk]\n",
        "test_x = x_df[~msk]\n",
        "test_y = y_df[~msk]\n",
        "\n",
        "train_norm_x = np.array(train_x)\n",
        "test_norm_x = np.array(test_x)\n",
        "\n",
        "test_norm_y = np.array(test_y)\n",
        "train_norm_y = np.array(train_y)\n",
        "\n",
        "train_norm_x = np.array(train_norm_x).astype(float)\n",
        "train_norm_y = np.array(train_norm_y).astype(float)\n",
        "test_norm_x = np.array(test_norm_x).astype(float)\n",
        "test_norm_y = np.array(test_norm_y).astype(float)\n",
        "\n",
        "print(train_norm_x.shape)\n",
        "print(test_norm_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59939, 1, 3, 4)\n",
            "(6534, 1, 3, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij35u6L92APQ",
        "colab_type": "text"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "daSca_7Y2APR",
        "colab_type": "code",
        "colab": {},
        "outputId": "3fd4de05-4bb2-4294-a75d-38d4de5c0da8"
      },
      "source": [
        "    TRAINING_ITERATIONS = 2000 #@param {type:\"number\"}\n",
        "    PLOT_AFTER = 500 #@param {type:\"number\"}\n",
        "    #HIDDEN_SIZE = random.choice([16, 32, 64, 128,256])\n",
        "    HIDDEN_SIZE = 128\n",
        "    MODEL_TYPE = 'NP' #@param ['NP','ANP']\n",
        "    ATTENTION_TYPE = 'multihead' #@param ['uniform','laplace','dot_product','multihead']\n",
        "    random_kernel_parameters=True #@param {type:\"boolean\"}\n",
        "    outc = 64\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    # Sizes of the layers of the MLPs for the encoders and decoder\n",
        "    # The final output layer of the decoder outputs two values, one for the mean and\n",
        "    # one for the variance of the prediction at the target location\n",
        "    latent_encoder_output_sizes = [HIDDEN_SIZE]*4\n",
        "    num_latents = HIDDEN_SIZE\n",
        "    deterministic_encoder_output_sizes= [HIDDEN_SIZE]*4\n",
        "    decoder_output_sizes = [HIDDEN_SIZE]*2 + [2]\n",
        "    use_deterministic_path = False\n",
        "\n",
        "    # ANP with multihead attention\n",
        "    if MODEL_TYPE == 'ANP':\n",
        "      attention = Attention(rep='mlp', output_sizes=[HIDDEN_SIZE]*2, \n",
        "                            att_type='multihead')\n",
        "    # NP - equivalent to uniform attention\n",
        "    elif MODEL_TYPE == 'NP':\n",
        "      attention = Attention(rep='identity', output_sizes=None, att_type='uniform')\n",
        "    else:\n",
        "      raise NameError(\"MODEL_TYPE not among ['ANP,'NP']\")\n",
        "\n",
        "    # Define the model\n",
        "    model = LatentModel(latent_encoder_output_sizes, num_latents,\n",
        "                        decoder_output_sizes, outc, use_deterministic_path, #outc between decoder and use\n",
        "                        deterministic_encoder_output_sizes, attention)\n",
        "    print(\"start wrapping data...\")\n",
        "    # Define data\n",
        "    batch_size = 100\n",
        "    #batch_size =  random.choice([5, 10, 25, 50, 100, 200, 400])\n",
        "    print(\"start wrapping training data...\")\n",
        "    train_query, train_target_y, train_num_total_points, train_num_context_points = datawrap(train_norm_x, train_norm_y, batch_size)\n",
        "    print(\"finish...\")\n",
        "    print(\"start wrapping testing data\")\n",
        "    test_query, test_target_y, test_num_total_points, test_num_context_points = testdatawrap(test_norm_x, test_norm_y, test_norm_x.shape[0])\n",
        "    print(\"finish wrapping data...\")\n",
        "    # Define the loss\n",
        "    _, _, log_prob, LL, _, loss = model(train_query, train_num_total_points,\n",
        "                                     train_target_y)\n",
        "\n",
        "    # Get the predicted mean and variance at the target points for the testing set\n",
        "    mu, sigma, _, _, _, validation_loss = model(test_query, test_num_total_points, test_target_y = test_target_y)\n",
        "\n",
        "    # Set up the optimizer and train step\n",
        "    optimizer = tf.train.AdamOptimizer(1e-3)\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    train_step = optimizer.minimize(loss, global_step=global_step)\n",
        "    init = tf.initialize_all_variables()\n",
        "\n",
        "    LL_set = []\n",
        "    LL_set_x = []\n",
        "    train_losses, test_losses = [],[]\n",
        "    best_train_loss = 99\n",
        "    best_val_loss = 99\n",
        "    print(\"start doing prediction...\")\n",
        "    saver = tf.train.Saver(max_to_keep=1)\n",
        "    # Train and plot\n",
        "    with tf.train.MonitoredTrainingSession(checkpoint_dir=\"./model/model.ckpt\", save_checkpoint_secs=600) as sess:\n",
        "      sess.run(init)\n",
        "      \n",
        "      ckpt = tf.train.get_checkpoint_state(\"./model/model.ckpt\")\n",
        "      if ckpt and ckpt.model_checkpoint_path:\n",
        "            # Restores from checkpoint\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "      \n",
        "      for it in range(TRAINING_ITERATIONS):\n",
        "        sess.run([train_step])\n",
        "\n",
        "        # Plot the predictions in `PLOT_AFTER` intervals\n",
        "        if it % PLOT_AFTER == 0:\n",
        "          validation_loss_value, loss_value, pred_y, std_y, target_y, whole_query, LL_value = sess.run(\n",
        "              [validation_loss, loss, mu, sigma, test_target_y, \n",
        "               test_query, LL])\n",
        "\n",
        "          # record LL in each itr\n",
        "          LL_set.append(LL_value)\n",
        "          #LL_set_X.append(itr)\n",
        "\n",
        "          plt.figure(figsize=(5,5)) \n",
        "          ratio_ct = 0.7\n",
        "          con_y = pred_y[:,:int(ratio_ct * test_num_total_points)] - target_y[:,:int(ratio_ct * test_num_total_points)]\n",
        "          tar_y = pred_y[:,int(ratio_ct * test_num_total_points):] - target_y[:,int(ratio_ct * test_num_total_points):]\n",
        "          X1 = np.arange(int(ratio_ct * test_num_total_points))\n",
        "          X2 = np.arange(int(ratio_ct * test_num_total_points),test_num_total_points)\n",
        "          s_con = plt.scatter(X1,con_y,color='red',s=0.3,label='context points')\n",
        "          s_tar = plt.scatter(X2,tar_y,color='blue',s=0.3,label='target points')\n",
        "          plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
        "              fancybox=True, shadow=True, ncol=4)\n",
        "          plt.xlabel('')\n",
        "          plt.ylabel('pred-target')\n",
        "          plt.title(r'distribution of pred-target')\n",
        "          plt.show()\n",
        "\n",
        "          (context_x, context_y), target_x = whole_query\n",
        "          print('Iteration: {}, train_loss: {}'.format(it, loss_value))\n",
        "          print('Iteration: {}, validation_loss: {}'.format(it, validation_loss_value))\n",
        "            \n",
        "          plt.figure(figsize=(5,5)) \n",
        "          plt.scatter(target_y, pred_y, s=0.1)\n",
        "          plt.xlabel('truth')\n",
        "          plt.ylabel('pred')\n",
        "          plt.ylim(-0.4,1)\n",
        "          plt.title(r'Parallax(truth) VS Parallax(pred)')\n",
        "          plt.show()\n",
        "        \n",
        "          train_losses.append(loss_value)\n",
        "          test_losses.append(validation_loss_value)\n",
        "          if loss_value < best_train_loss:\n",
        "            best_train_loss = loss_value\n",
        "          if validation_loss_value < best_val_loss:\n",
        "            best_val_loss = validation_loss_value\n",
        "\n",
        "    print('best training loss:')\n",
        "    print(best_train_loss)\n",
        "    print('best validation loss:')\n",
        "    print(best_val_loss)\n",
        "    print('hidden size:')\n",
        "    print(HIDDEN_SIZE)\n",
        "    print('batch size:')\n",
        "    print(batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start wrapping data...\n",
            "start wrapping training data...\n",
            "finish...\n",
            "start wrapping testing data\n",
            "finish wrapping data...\n",
            "start doing prediction...\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./model/model.ckpt/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into ./model/model.ckpt/model.ckpt.\n",
            "INFO:tensorflow:Restoring parameters from ./model/model.ckpt/model.ckpt-2000\n",
            "INFO:tensorflow:global_step/sec: 870.822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0, train_loss: -0.9892523288726807\n",
            "Iteration: 0, validation_loss: -0.9959856867790222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-fc932539d1ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_ITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Plot the predictions in `PLOT_AFTER` intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk16LGIa2APT",
        "colab_type": "text"
      },
      "source": [
        "# MLAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL2Oc4AG2APU",
        "colab_type": "text"
      },
      "source": [
        "## 1. RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7eu6RWE2APV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RMSE = sqrt(1/N * sum(  (d_true - d_pred)/d_true))^2 )\n",
        "def cal_RMSE(true, prediction):\n",
        "    return np.sqrt((1/(true.shape[0])) * np.square(np.sum((true-prediction)/true)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNeQPaSL2APX",
        "colab_type": "text"
      },
      "source": [
        "## 2. Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVQu77yu2APX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BIAS = 1/N * sum( (d_true-d_pred)/d_true )\n",
        "def cal_bias(true, prediction):\n",
        "    return (1/(true.shape[0])) * np.sum(np.sum((true-prediction)/true))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3zTwGWs2APZ",
        "colab_type": "text"
      },
      "source": [
        "## 3. SIGMA_NMAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Ze7rgU2APa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SIGMA_NMAD = 1.48 * median(d_true-d_pred)/d_true)\n",
        "def cal_sigma_nmad(true, prediction):\n",
        "    return 1.48 * np.median((true-prediction)/true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2evFzA-2APc",
        "colab_type": "text"
      },
      "source": [
        "## 4. fraction_of_outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0oiBihn2APc",
        "colab_type": "code",
        "colab": {},
        "outputId": "ba49f320-4255-4eac-ab65-c1c2a1add346"
      },
      "source": [
        "def cal_fraction_of_outliers(true, prediction):\n",
        "    res = np.abs(true-prediction)\n",
        "    outlier_sigmas = 0.3\n",
        "    spread = np.std(res)\n",
        "    print(spread)\n",
        "    return np.sum(res > (outlier_sigmas*spread))\n",
        "\n",
        "cal_fraction_of_outliers(np.array([1,2,3]),np.array([2,3,4]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkB-m2v42APe",
        "colab_type": "text"
      },
      "source": [
        "# my  model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc943Pqm2APe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvEncoder(object):\n",
        "  def __init__(self, num_latents, output_sizes, outc):\n",
        "    \"\"\"Convolutional encoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the encoding MLP.\n",
        "      num_latents: The latent dimensionality.\n",
        "    \"\"\"\n",
        "    self._num_latents = num_latents\n",
        "    self.conv = Conv2D(2, kernel_size=1)\n",
        "    self.conv1 = Conv2D(2, kernel_size=1)\n",
        "    self._output_sizes = output_sizes\n",
        "    self.conv2 = Conv2D(outc, kernel_size=1)\n",
        "    self.conv2a = Conv2D(outc, kernel_size=1)\n",
        "\n",
        "    self.conv2b = Conv2D(outc, kernel_size=1)\n",
        "\n",
        "    self.conv2c = Conv2D(outc, kernel_size=1, activation='relu')\n",
        "\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "  def __call__(self, x, y):\n",
        "    \"\"\"Encodes the inputs into one representation.\n",
        "\n",
        "    Args:\n",
        "      x: Tensor of shape [B, N, H, W, C]. For this 1D regression\n",
        "          task this corresponds to the x-values.\n",
        "      y: Tensor of shape [B, N, d_y]. For this 1D regression\n",
        "          task this corresponds to the y-values.\n",
        "\n",
        "    Returns:\n",
        "      A normal distribution over tensors of shape [B, num_latents]\n",
        "    \"\"\"\n",
        "    # Have further MLP layers that map to the parameters of the Gaussian latent\n",
        "    def acn(x):\n",
        "        eps = 1e-5\n",
        "        acn = True\n",
        "        if acn:\n",
        "            attention = self.conv1(x)\n",
        "            att1 = tf.reshape(attention[:,:,:,0], (attention.shape[0], -1))\n",
        "            att2 = tf.reshape(attention[:,:,:,1], (attention.shape[0], -1))\n",
        "            a_l = tf.nn.sigmoid(att1, name='sigmoid')\n",
        "            a_r = tf.nn.softmax(att2, axis=1)\n",
        "            \n",
        "            a = a_l * a_r\n",
        "            \n",
        "        else:\n",
        "            a = tf.ones([x.shape[0], x.shape[1] * x.shape[2]], tf.float32)\n",
        "        a = a/(tf.reduce_sum(a, 1)[..., None] + eps)\n",
        "        #a = a / (a.sum(dim=1)[..., None] + eps)\n",
        "        #a = a.view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        \n",
        "        a = tf.reshape(a,((x.shape[0], x.shape[1], x.shape[2], 1)))\n",
        "        \n",
        "        #mean = torch.sum(x * a, dim=(2, 3), keepdim=True)\n",
        "        mean = tf.reduce_sum(x*a, (1,2), keepdims=True)\n",
        "        \n",
        "        out = x - mean\n",
        "        #std = torch.sqrt(torch.sum(a * out**2, dim=(2, 3), keepdim=True) + eps)\n",
        "        std = tf.sqrt(tf.reduce_sum(a * out**2, (1,2), keepdims=True) + eps)\n",
        "        out = out / std\n",
        "        return out\n",
        "    \n",
        "    def acn2(x):\n",
        "        eps = 1e-5\n",
        "        acn = True\n",
        "\n",
        "        if acn:\n",
        "            attention = self.conv(x)\n",
        "            att1 = tf.reshape(attention[:,:,:,0], (attention.shape[0], -1))\n",
        "            att2 = tf.reshape(attention[:,:,:,1], (attention.shape[0], -1))\n",
        "            a_l = tf.nn.sigmoid(att1, name='sigmoid')\n",
        "            a_r = tf.nn.softmax(att2, axis=1)\n",
        "            \n",
        "            a = a_l * a_r\n",
        "            \n",
        "        else:\n",
        "            a = tf.ones([x.shape[0], x.shape[1] * x.shape[2]], tf.float32)\n",
        "            \n",
        "        a = a/(tf.reduce_sum(a, 1)[..., None] + eps)\n",
        "        #a = a / (a.sum(dim=1)[..., None] + eps)\n",
        "        #a = a.view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        \n",
        "        a = tf.reshape(a,((x.shape[0], x.shape[1], x.shape[2], 1)))\n",
        "        \n",
        "        #mean = torch.sum(x * a, dim=(2, 3), keepdim=True)\n",
        "        mean = tf.reduce_sum(x*a, (1,2), keepdims=True)\n",
        "        \n",
        "        return mean\n",
        "    \n",
        "    def acn3(x):\n",
        "        eps = 1e-5\n",
        "        acn = True\n",
        "\n",
        "        if acn:\n",
        "            attention = self.conv1(x)\n",
        "            att1 = tf.reshape(attention[:,:,:,0], (attention.shape[0], -1))\n",
        "            att2 = tf.reshape(attention[:,:,:,1], (attention.shape[0], -1))\n",
        "            a_l = tf.nn.sigmoid(att1, name='sigmoid')\n",
        "            a_r = tf.nn.softmax(att2, axis=1)\n",
        "            \n",
        "            a = a_l * a_r\n",
        "            \n",
        "        else:\n",
        "            a = tf.ones([x.shape[0], x.shape[1] * x.shape[2]], tf.float32)\n",
        "            \n",
        "        a = a/(tf.reduce_sum(a, 1)[..., None] + eps)\n",
        "        #a = a / (a.sum(dim=1)[..., None] + eps)\n",
        "        #a = a.view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        \n",
        "        a = tf.reshape(a,((x.shape[0], x.shape[1], x.shape[2], 1)))\n",
        "        \n",
        "        #mean = torch.sum(x * a, dim=(2, 3), keepdim=True)\n",
        "        mean = tf.reduce_sum(x*a, (1,2), keepdims=True)\n",
        "        \n",
        "        return mean\n",
        "    \n",
        "    with tf.Session():\n",
        "        X = x.eval()\n",
        "        #y = y.eval()\n",
        "\n",
        "    #X = np.reshape(X, (x.shape[0]*x.shape[1], x.shape[2], x.shape[3], x.shape[4]))\n",
        "    X = np.reshape(X, (x.shape[0]*x.shape[1], x.shape[2], x.shape[3], -1))\n",
        "    #y = np.reshape(y, (y.shape[0]*y.shape[1], y.shape[2]))\n",
        "    \n",
        "    X = tf.convert_to_tensor(X, np.float32)\n",
        "    #y = tf.convert_to_tensor(y, np.float32)\n",
        "    with tf.variable_scope(\"conv_encoder\", reuse=tf.AUTO_REUSE):\n",
        "      #X = self.conv2(X)\n",
        "      X = self.conv2a(X)\n",
        "      X = self.conv2b(X)\n",
        "      X = self.conv2c(X)\n",
        "      X = acn2(X)\n",
        "      X = self.flatten(X)\n",
        "      X = tf.reshape(X,(x.shape[0], x.shape[1], X.shape[1]))\n",
        "      X = tf.concat([X, y], axis=-1)\n",
        "    \n",
        "    hidden = batch_mlp(X, self._output_sizes, \"latent_encoder\")\n",
        "\n",
        "    # Aggregator: take the mean over all points\n",
        "    hidden = tf.reduce_mean(hidden, axis=1)\n",
        "    \n",
        "    # Have further MLP layers that map to the parameters of the Gaussian latent\n",
        "    with tf.variable_scope(\"latent_encoder\", reuse=tf.AUTO_REUSE):\n",
        "      # First apply intermediate relu layer \n",
        "      hidden = tf.nn.relu(\n",
        "          tf.layers.dense(hidden, \n",
        "                          (self._output_sizes[-1] + self._num_latents)/2,\n",
        "                          name=\"penultimate_layer\"))\n",
        "      # Then apply further linear layers to output latent mu and log sigma\n",
        "      mu = tf.layers.dense(hidden, self._num_latents, name=\"mean_layer\")\n",
        "      log_sigma = tf.layers.dense(hidden, self._num_latents, name=\"std_layer\")\n",
        "      \n",
        "    # Compute sigma\n",
        "    sigma = 0.1 + 0.9 * tf.sigmoid(log_sigma)\n",
        "\n",
        "    return tf.contrib.distributions.Normal(loc=mu, scale=sigma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1SWqwPd2APg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LatentModel(object):\n",
        "  \"\"\"The (A)NP model.\"\"\"\n",
        "\n",
        "  def __init__(self, latent_encoder_output_sizes, num_latents,\n",
        "               decoder_output_sizes, outc, use_deterministic_path=True, \n",
        "               deterministic_encoder_output_sizes=None, attention=None):\n",
        "    \"\"\"Initialises the model.\n",
        "\n",
        "    Args:\n",
        "      latent_encoder_output_sizes: An iterable containing the sizes of hidden \n",
        "          layers of the latent encoder.\n",
        "      num_latents: The latent dimensionality.\n",
        "      decoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
        "          the decoder. The last element should correspond to d_y * 2\n",
        "          (it encodes both mean and variance concatenated)\n",
        "      use_deterministic_path: a boolean that indicates whether the deterministic\n",
        "          encoder is used or not.\n",
        "      deterministic_encoder_output_sizes: An iterable containing the sizes of \n",
        "          hidden layers of the deterministic encoder. The last one is the size \n",
        "          of the deterministic representation r.\n",
        "      attention: The attention module used in the deterministic encoder.\n",
        "          Only relevant when use_deterministic_path=True.\n",
        "    \"\"\"\n",
        "    self._conv_encoder = ConvEncoder(num_latents, latent_encoder_output_sizes, outc)\n",
        "    self._decoder = Decoder(decoder_output_sizes)\n",
        "    self._use_deterministic_path = use_deterministic_path\n",
        "    if use_deterministic_path:\n",
        "      self._deterministic_encoder = DeterministicEncoder(\n",
        "          deterministic_encoder_output_sizes, attention)\n",
        "    \n",
        "\n",
        "  def __call__(self, query, num_targets, target_y=None, test_target_y=None):\n",
        "    \"\"\"Returns the predicted mean and variance at the target points.\n",
        "\n",
        "    Args:\n",
        "      query: Array containing ((context_x, context_y), target_x) where:\n",
        "          context_x: Tensor of shape [B,num_contexts,d_x]. \n",
        "              Contains the x values of the context points.\n",
        "          context_y: Tensor of shape [B,num_contexts,d_y]. \n",
        "              Contains the y values of the context points.\n",
        "          target_x: Tensor of shape [B,num_targets,d_x]. \n",
        "              Contains the x values of the target points.\n",
        "      num_targets: Number of target points.\n",
        "      target_y: The ground truth y values of the target y. \n",
        "          Tensor of shape [B,num_targets,d_y].\n",
        "\n",
        "    Returns:\n",
        "      log_p: The log_probability of the target_y given the predicted\n",
        "          distribution. Tensor of shape [B,num_targets].\n",
        "      mu: The mean of the predicted distribution. \n",
        "          Tensor of shape [B,num_targets,d_y].\n",
        "      sigma: The variance of the predicted distribution.\n",
        "          Tensor of shape [B,num_targets,d_y].\n",
        "    \"\"\"\n",
        "\n",
        "    (context_x, context_y), target_x = query\n",
        "\n",
        "    # Pass query through the encoder and the decoder\n",
        "    prior = self._conv_encoder(context_x, context_y)\n",
        "    \n",
        "    # For training, when target_y is available, use targets for latent encoder.\n",
        "    # Note that targets contain contexts by design.\n",
        "    if target_y is None:\n",
        "      latent_rep = prior.sample()\n",
        "    # For testing, when target_y unavailable, use contexts for latent encoder.\n",
        "    else:\n",
        "      posterior = self._conv_encoder(target_x, target_y)\n",
        "      latent_rep = posterior.sample()\n",
        "    latent_rep = tf.tile(tf.expand_dims(latent_rep, axis=1),\n",
        "                         [1, num_targets, 1])\n",
        "    if self._use_deterministic_path:\n",
        "      deterministic_rep = self._deterministic_encoder(context_x, context_y,\n",
        "                                                      target_x)\n",
        "      representation = tf.concat([deterministic_rep, latent_rep], axis=-1)\n",
        "    else:\n",
        "      representation = latent_rep\n",
        "\n",
        "    dist, mu, sigma = self._decoder(representation, target_x)\n",
        "    \n",
        "    # If we want to calculate the log_prob for training we will make use of the\n",
        "    # target_y. At test time the target_y is not available so we return None.\n",
        "    if target_y is not None:\n",
        "      log_p = dist.log_prob(target_y)\n",
        "      posterior = self._conv_encoder(target_x, target_y)\n",
        "      kl = tf.reduce_sum(\n",
        "          tf.contrib.distributions.kl_divergence(posterior, prior), \n",
        "          axis=-1, keepdims=True)\n",
        "      kl = tf.tile(kl, [1, num_targets])\n",
        "      loss = - tf.reduce_mean(log_p - kl / tf.cast(num_targets, tf.float32))\n",
        "      LL = tf.reduce_mean(log_p, keep_dims=False)\n",
        "    else:\n",
        "      log_p = dist.log_prob(test_target_y)\n",
        "      posterior = self._conv_encoder(target_x, test_target_y)\n",
        "      kl = tf.reduce_sum(\n",
        "          tf.contrib.distributions.kl_divergence(posterior, prior), \n",
        "          axis=-1, keepdims=True)\n",
        "      kl = tf.tile(kl, [1, num_targets])\n",
        "      loss = - tf.reduce_mean(log_p - kl / tf.cast(num_targets, tf.float32))\n",
        "      #validation_context_loss = - tf.reduce_mean(log_p[:,int(0.5*num_targets):] - kl / tf.cast(num_targets, tf.float32))\n",
        "      #validation_noncontext_loss =  - tf.reduce_mean(log_p - kl / tf.cast(num_targets, tf.float32))\n",
        "      LL = None\n",
        "        #con_y = pred_y[:,:int(0.5 * test_num_total_points)] - target_y[:,:int(0.5 * test_num_total_points)]\n",
        "      #tar_y = pred_y[:,int(0.5 * test_num_total_points):] - target_y[:,int(0.5 * test_num_total_points):]\n",
        "\n",
        "    return mu, sigma, log_p, LL, kl, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T_wYDIA2APh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(object):\n",
        "  \"\"\"The Decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, output_sizes):\n",
        "    \"\"\"(A)NP decoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the decoder MLP \n",
        "          as defined in `basic.Linear`.\n",
        "    \"\"\"\n",
        "    self._output_sizes = output_sizes\n",
        "    self._num_latents = 128\n",
        "    self.conv = Conv2D(2, kernel_size=1)\n",
        "    self.conv1 = Conv2D(2, kernel_size=1)\n",
        "    outc = 64\n",
        "    self.conv2 = Conv2D(outc, kernel_size=1)\n",
        "    self.conv2a = Conv2D(outc, kernel_size=1)\n",
        "\n",
        "    self.conv2b = Conv2D(outc, kernel_size=1)\n",
        "\n",
        "    self.conv2c = Conv2D(outc, kernel_size=1, activation='relu')\n",
        "\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "  def __call__(self, representation, target_x):\n",
        "    \"\"\"Decodes the individual targets.\n",
        "\n",
        "    Args:\n",
        "      representation: The representation of the context for target predictions. \n",
        "          Tensor of shape [B,target_observations,?].\n",
        "      target_x: The x locations for the target query.\n",
        "          Tensor of shape [B,target_observations,d_x].\n",
        "\n",
        "    Returns:\n",
        "      dist: A multivariate Gaussian over the target points. A distribution over\n",
        "          tensors of shape [B,target_observations,d_y].\n",
        "      mu: The mean of the multivariate Gaussian.\n",
        "          Tensor of shape [B,target_observations,d_x].\n",
        "      sigma: The standard deviation of the multivariate Gaussian.\n",
        "          Tensor of shape [B,target_observations,d_x].\n",
        "    \"\"\"\n",
        "    # concatenate target_x and representation\n",
        "    def acn(x):\n",
        "        eps = 1e-5\n",
        "        acn = True\n",
        "        if acn:\n",
        "            attention = self.conv1(x)\n",
        "            att1 = tf.reshape(attention[:,:,:,0], (attention.shape[0], -1))\n",
        "            att2 = tf.reshape(attention[:,:,:,1], (attention.shape[0], -1))\n",
        "            a_l = tf.nn.sigmoid(att1, name='sigmoid')\n",
        "            a_r = tf.nn.softmax(att2, axis=1)\n",
        "            \n",
        "            a = a_l * a_r\n",
        "            \n",
        "        else:\n",
        "            a = tf.ones([x.shape[0], x.shape[1] * x.shape[2]], tf.float32)\n",
        "            \n",
        "        a = a/(tf.reduce_sum(a, 1)[..., None] + eps)\n",
        "        #a = a / (a.sum(dim=1)[..., None] + eps)\n",
        "        #a = a.view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        \n",
        "        a = tf.reshape(a,((x.shape[0], x.shape[1], x.shape[2], 1)))\n",
        "        #mean = torch.sum(x * a, dim=(2, 3), keepdim=True)\n",
        "        mean = tf.reduce_sum(x*a, (1,2), keepdims=True)\n",
        "        out = x - mean\n",
        "        #std = torch.sqrt(torch.sum(a * out**2, dim=(2, 3), keepdim=True) + eps)\n",
        "        std = tf.sqrt(tf.reduce_sum(a * out**2, (1,2), keepdims=True) + eps)\n",
        "        out = out / std\n",
        "        return out\n",
        "    \n",
        "    def acn2(x):\n",
        "        eps = 1e-5\n",
        "        acn = True\n",
        "        if acn:\n",
        "            attention = self.conv(x)\n",
        "            att1 = tf.reshape(attention[:,:,:,0], (attention.shape[0], -1))\n",
        "            att2 = tf.reshape(attention[:,:,:,1], (attention.shape[0], -1))\n",
        "            a_l = tf.nn.sigmoid(att1, name='sigmoid')\n",
        "            a_r = tf.nn.softmax(att2, axis=1)\n",
        "            \n",
        "            a = a_l * a_r\n",
        "            \n",
        "        else:\n",
        "            a = tf.ones([x.shape[0], x.shape[1] * x.shape[2]], tf.float32)\n",
        "\n",
        "        a = a/(tf.reduce_sum(a, 1)[..., None] + eps)\n",
        "        #a = a / (a.sum(dim=1)[..., None] + eps)\n",
        "        #a = a.view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        \n",
        "        a = tf.reshape(a,((x.shape[0], x.shape[1], x.shape[2], 1)))\n",
        "        \n",
        "        #mean = torch.sum(x * a, dim=(2, 3), keepdim=True)\n",
        "        mean = tf.reduce_sum(x*a, (1,2), keepdims=True)\n",
        "        \n",
        "        return mean \n",
        "    \n",
        "    def acn3(x):\n",
        "        eps = 1e-5\n",
        "        acn = True\n",
        "\n",
        "        if acn:\n",
        "            attention = self.conv1(x)\n",
        "            att1 = tf.reshape(attention[:,:,:,0], (attention.shape[0], -1))\n",
        "            att2 = tf.reshape(attention[:,:,:,1], (attention.shape[0], -1))\n",
        "            a_l = tf.nn.sigmoid(att1, name='sigmoid')\n",
        "            a_r = tf.nn.softmax(att2, axis=1)\n",
        "            \n",
        "            a = a_l * a_r\n",
        "            \n",
        "        else:\n",
        "            a = tf.ones([x.shape[0], x.shape[1] * x.shape[2]], tf.float32)\n",
        "            \n",
        "        a = a/(tf.reduce_sum(a, 1)[..., None] + eps)\n",
        "        #a = a / (a.sum(dim=1)[..., None] + eps)\n",
        "        #a = a.view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        \n",
        "        a = tf.reshape(a,((x.shape[0], x.shape[1], x.shape[2], 1)))\n",
        "        \n",
        "        #mean = torch.sum(x * a, dim=(2, 3), keepdim=True)\n",
        "        mean = tf.reduce_sum(x*a, (1,2), keepdims=True)\n",
        "        \n",
        "        return mean   \n",
        "    \n",
        "    x = target_x\n",
        "    \n",
        "    with tf.Session():\n",
        "        X = x.eval()\n",
        "        #y = y.eval()\n",
        "\n",
        "    #X = np.reshape(X, (x.shape[0]*x.shape[1], x.shape[2], x.shape[3], x.shape[4]))\n",
        "    X = np.reshape(X, (x.shape[0]*x.shape[1], x.shape[2], x.shape[3], -1))\n",
        "    #y = np.reshape(y, (y.shape[0]*y.shape[1], y.shape[2]))\n",
        "    \n",
        "    X = tf.convert_to_tensor(X, np.float32)\n",
        "    #y = tf.convert_to_tensor(y, np.float32)\n",
        "\n",
        "    with tf.variable_scope(\"conv_encoder\", reuse=tf.AUTO_REUSE):\n",
        "      #X = self.conv2(X)\n",
        "      X = self.conv2a(X)\n",
        "      X = self.conv2b(X)\n",
        "      X = self.conv2c(X)\n",
        "      X = acn2(X)\n",
        "      X = self.flatten(X)\n",
        "      X = tf.reshape(X,(x.shape[0], x.shape[1], X.shape[1]))\n",
        "      #X = tf.concat([X, y], axis=-1)\n",
        "    target_x = tf.reshape(target_x, (target_x.shape[0], target_x.shape[1], -1))\n",
        "\n",
        "    hidden = tf.concat([representation, X], axis=-1)\n",
        "    #print(representation.shape)\n",
        "    #hidden = target_x\n",
        "    #hidden = representation\n",
        "    \n",
        "    # Pass final axis through MLP\n",
        "    hidden = batch_mlp(hidden, self._output_sizes, \"decoder\")\n",
        "\n",
        "    # Get the mean an the variance\n",
        "    mu, log_sigma = tf.split(hidden, 2, axis=-1)\n",
        "\n",
        "    # Bound the variance\n",
        "    sigma = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
        "\n",
        "    # Get the distribution\n",
        "    dist = tf.contrib.distributions.MultivariateNormalDiag(\n",
        "        loc=mu, scale_diag=sigma)\n",
        "\n",
        "    return dist, mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV2EEIBW2APj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}