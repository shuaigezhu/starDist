{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForestStar.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuaigezhu/starDist/blob/master/RandomForestStar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zso-FGwEd4-Q",
        "colab_type": "code",
        "outputId": "6607d566-3c75-4b06-c960-733b4705bef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from math import pi\n",
        "from random import randint\n",
        "from torch import nn\n",
        "from torch.distributions.kl import kl_divergence\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#!unzip -q \"/content/gaia_pos.zip\"\n",
        "# Get data file names\n",
        "path =r'/content/gaia_pos'\n",
        "filenames = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "dfs = []\n",
        "error_dfs = []\n",
        "\n",
        "\n",
        "def Normalization(data):\n",
        "  data_f = data.astype(float)\n",
        "  data_mean = np.mean(data_f, axis=0, keepdims=True)\n",
        "  data_n = data_f - data_mean\n",
        "  data_range = np.max(np.abs(data_n), axis=0, keepdims=True)\n",
        "  data_n = data_n / data_range\n",
        "  \n",
        "  return data_n\n",
        "\n",
        "# Select specific colomns which are \"ra\", \"dec\", \"magnitude\", \"wavelength\" and \"parallax\" and \"parallax error\"\n",
        "\n",
        "for filename in filenames:\n",
        "  data = pd.read_csv(filename, header=None)\n",
        "  select_data = data.iloc[1:,[2, 4, 10, 11, 6]]\n",
        "  parallax_error = data.iloc[1:,[7]]\n",
        "  \n",
        "  dfs.append(select_data)\n",
        "  error_dfs.append(parallax_error)\n",
        "\n",
        "# Combine the three files of the different type of filter into one pandas framework\n",
        "\n",
        "frame = pd.concat(dfs, axis=0, ignore_index=True, sort = False)\n",
        "parallax_error_frame = pd.concat(error_dfs, axis=0, ignore_index=True, sort = False)\n",
        "\n",
        "frame = frame.rename(columns={2: \"ra\", 4: \"dec\", 10: \"magnitude\", 11: \"wavelength\", 6: \"parallax\"})\n",
        "parallax_error_frame = parallax_error_frame.rename(columns={7:\"parallax error\"})\n",
        "#print(parallax_error_frame.head())\n",
        "\n",
        "# Split the dataset into training and testing part.\n",
        "ratio = 0.9 #the ratio is train/all \n",
        "msk = np.random.rand(len(frame)) < ratio\n",
        "train_frame = frame[msk]\n",
        "test_frame = frame[~msk]\n",
        "parallax_error_test_frame = parallax_error_frame[~msk]\n",
        "\n",
        "def split_into_xy(dataframe):  \n",
        "  x = dataframe.iloc[:, [0,1,2,3]]\n",
        "  y = dataframe.iloc[:, [4]]\n",
        "  \n",
        "  return x , y\n",
        "\n",
        "train_x, train_y = split_into_xy(train_frame)\n",
        "test_x, test_y = split_into_xy(test_frame)\n",
        "\n",
        "#convert into numpy array and type of float\n",
        "train_x = np.array(train_x)\n",
        "train_x = train_x.astype(float)\n",
        "train_y = np.array(train_y)\n",
        "train_y = train_y.astype(float)\n",
        "\n",
        "test_x = np.array(test_x)\n",
        "test_x = test_x.astype(float)\n",
        "test_y = np.array(test_y)\n",
        "test_y = test_y.astype(float)\n",
        "\n",
        "test_parallax_error = np.array(parallax_error_test_frame).astype(float)\n",
        "\n",
        "r_scaler = preprocessing.RobustScaler()\n",
        "train_norm_x = Normalization(train_x)\n",
        "train_norm_y = train_y\n",
        "#train_norm_y = r_scaler.fit_transform(train_y)\n",
        "test_norm_x = Normalization(test_x)\n",
        "test_norm_y = test_y\n",
        "#test_norm_y = r_scaler.fit_transform(test_y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzL5_K1tgDHS",
        "colab_type": "code",
        "outputId": "2c702f27-5b70-4956-a420-25e0d08bb948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_norm_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(819681, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU1vYGaqfMaQ",
        "colab_type": "text"
      },
      "source": [
        "### **random forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Up7S5gfaOw",
        "colab_type": "code",
        "outputId": "34243a2e-437c-42e7-c607-80d3ee422e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "locations = np.random.choice(train_norm_x.shape[0],\n",
        "                                 size=100000,\n",
        "                                 replace=False)\n",
        "\n",
        "X = train_norm_x[locations,:]\n",
        "Y = train_norm_y[locations,:]\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
        "rf.fit(X, np.reshape(Y,Y.shape[0])) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3F0WQm8ij7w",
        "colab_type": "code",
        "outputId": "c45696af-e371-4b2a-903b-1f6ed537e9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predictions = rf.predict(test_norm_x)\n",
        "tmp = np.reshape(test_norm_y, test_norm_y.shape[0])\n",
        "print (np.median(1-(abs(tmp - predictions)/predictions)))\n",
        "\n",
        "print(predictions)\n",
        "print(tmp)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.457948723414777\n",
            "[1.33217432 0.8397331  1.42876108 ... 1.46013703 1.47429116 1.39596781]\n",
            "[2.39696324 0.85392091 0.43093035 ... 0.19094035 0.28485553 0.38405779]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPssCZ93udq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d6777ac2-c1f3-4314-d0b8-7f722bdee8a7"
      },
      "source": [
        "\n",
        "print(test_norm_x[:,2])\n",
        "print(test_norm_y)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.14875511  0.07114928 -0.19000589 ... -0.04255316 -0.06606188\n",
            "  0.17827017]\n",
            "[[2.39696324]\n",
            " [0.85392091]\n",
            " [0.43093035]\n",
            " ...\n",
            " [0.19094035]\n",
            " [0.28485553]\n",
            " [0.38405779]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LeJ246G3qKJ",
        "colab_type": "text"
      },
      "source": [
        "### **Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4IOpavv6vjM",
        "colab_type": "code",
        "outputId": "f1d13d50-02fc-4e42-f098-c119663b103a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#locations = np.random.choice(train_norm_x.shape[0],\n",
        " #                                size=100000,\n",
        "  #                               replace=False)\n",
        "\n",
        "#X = train_norm_x[locations,:]\n",
        "#Y = train_norm_y[locations,:]\n",
        "X = train_norm_x\n",
        "Y = train_norm_y\n",
        "Y_test = np.reshape(test_norm_y, test_norm_y.shape[0])\n",
        "X_test = test_norm_x\n",
        "lm = linear_model.LinearRegression()\n",
        "model = lm.fit(X, Y)\n",
        "predictions = lm.predict(X_test)\n",
        "print(\"Size of dataframe: \" + str(X.shape[0]))\n",
        "print(\"Polynomial regression:\")\n",
        "print(\"\\tDegree = 1,  Score = \" + str(model.score(X_test, Y_test)))\n",
        "degree_max = 5\n",
        "\n",
        "for d in range(2, degree_max + 1):\n",
        "    print(\"\\tDegree = \" + str(d), end=\"\")\n",
        "    polynomial_features = PolynomialFeatures(degree=d, interaction_only=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    X_poly = polynomial_features.fit_transform(X)\n",
        "    model=linear_regression.fit(X_poly, Y)\n",
        "    X_test_poly = polynomial_features.fit_transform(X_test)\n",
        "    Y_test_pred = linear_regression.predict(X_test_poly)\n",
        "    print(\",  Score = \" + str(model.score(X_test_poly, Y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of dataframe: 819681\n",
            "Polynomial regression:\n",
            "\tDegree = 1,  Score = 0.022743585395110122\n",
            "\tDegree = 2,  Score = 0.06458923811743333\n",
            "\tDegree = 3,  Score = -10.515556709259242\n",
            "\tDegree = 4,  Score = -1.3331380207557933e+19\n",
            "\tDegree = 5,  Score = -1.2725886278644527e+19\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}